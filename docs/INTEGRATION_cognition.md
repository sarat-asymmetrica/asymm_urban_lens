# üß† COGNITION ENGINE - Integration Guide

**Ported from:** `asymm_ananta/backend/internal/cognition/`
**To:** `asymm_urbanlens/pkg/cognition/`
**Date:** December 26, 2025

---

## üéØ What Is This?

The **Cognition Engine** enables **observable AI reasoning** - streaming the AI's internal thought processes in real-time at **Tesla's harmonic frequency** (4.909 Hz = 203.9ms intervals).

This is the **"thinking out loud"** capability that makes Asya's reasoning transparent, inspectable, and mathematically rigorous.

---

## üì¶ What Was Copied

| File | Lines | Purpose |
|------|-------|---------|
| `types.go` | 308 | Core types, events, state structures |
| `store.go` | 218 | In-memory quaternion concept store |
| `observer.go` | 463 | Real-time thought stream observer (Tesla 4.909 Hz) |
| `observable_emitter.go` | 316 | Bridge VOID‚ÜíFLOW‚ÜíSOLUTION to WebSocket |
| `websocket.go` | 308 | WebSocket server for real-time streaming |
| `intervention.go` | 272 | Mid-process reasoning steering |
| `recorder.go` | 358 | Record/replay cognition sessions |
| `visualization.go` | 392 | D3.js-ready visualization data |
| **TOTAL** | **~2,635 LOC** | **Complete observable cognition system** |

### Key Adaptations

1. **Import paths** changed from:
   - `github.com/asymmetrica/ananta/internal/storage` ‚Üí `pkg/cognition` (in-memory store)
   - `github.com/asymmetrica/ananta/internal/vedic` ‚Üí `github.com/asymmetrica/urbanlens/pkg/vqc`

2. **Regime types** moved from storage package to local cognition types
3. **Quaternion primitives** now use Urban Lens's existing `pkg/vqc` package
4. **In-memory store** created (Urban Lens doesn't have PostgreSQL storage yet)

---

## üîó Integration Opportunities

### 1. **Stream Cognition Events to Chat** (`pkg/conversation`)

**Current state:**
`pkg/conversation/engine.go` has a conversation engine that processes messages.

**Integration:**
```go
// pkg/conversation/engine.go

import "github.com/asymmetrica/urbanlens/pkg/cognition"

type ConversationEngine struct {
    // Existing fields...
    cognitionObserver *cognition.CognitionObserver
    emitter           *cognition.ObservableEmitter
}

func (ce *ConversationEngine) ProcessMessage(ctx context.Context, message string) error {
    sessionID := uuid.New().String()

    // Start cognition observation
    stream, err := ce.cognitionObserver.StartObserving(ctx, sessionID)
    if err != nil {
        return err
    }
    defer ce.cognitionObserver.StopObserving(sessionID)

    // Emit thinking events as reasoning progresses
    ce.emitter.EmitVoidState(ctx, sessionID, "Understanding your question...")

    // Do reasoning...

    ce.emitter.EmitFlowState(ctx, sessionID, "Processing patterns...")

    // Generate response...

    ce.emitter.EmitSolutionState(ctx, sessionID, "Complete!")

    return nil
}
```

**Benefit:** Users see Asya's reasoning process in real-time, not just the final answer.

---

### 2. **Asya's Inner Voice** (`pkg/persona`)

**Current state:**
`pkg/persona/asya.go` defines Asya's persona with tone, multilingual support, analogies.

**Integration:**
```go
// pkg/persona/asya.go

import "github.com/asymmetrica/urbanlens/pkg/cognition"

func (a *Asya) ThinkOutLoud(ctx context.Context, sessionID string, thought string) error {
    // Emit internal monologue to cognition stream
    return a.cognitionObserver.EmitThought(sessionID, thought, "üí≠")
}

func (a *Asya) AnalyzeQuestion(ctx context.Context, sessionID, question string) (*Response, error) {
    a.ThinkOutLoud(ctx, sessionID, "Let me understand what you're asking...")

    // Detect language
    lang := a.i18n.DetectLanguage(question)
    a.ThinkOutLoud(ctx, sessionID, fmt.Sprintf("Detected language: %s", lang))

    // Choose analogy style
    a.ThinkOutLoud(ctx, sessionID, "Finding the right analogy for this...")

    // Generate response
    return response, nil
}
```

**Benefit:** Asya's personality becomes **observable**. Users see not just what she says, but **how she thinks**.

---

### 3. **Show Thinking While Waiting for LLM** (`pkg/aimlapi`)

**Current state:**
`pkg/aimlapi/client.go` streams LLM responses, but there's latency before first token.

**Integration:**
```go
// pkg/aimlapi/client.go

func (c *Client) StreamCompletion(ctx context.Context, req CompletionRequest) (<-chan string, error) {
    sessionID := req.SessionID // Add SessionID to request

    // Emit cognition events during LLM processing
    c.emitter.EmitProgress(ctx, sessionID, 0.0, "Sending request to LLM...")
    c.emitter.EmitProgress(ctx, sessionID, 0.1, "Waiting for model...")

    // When streaming starts
    c.emitter.EmitProgress(ctx, sessionID, 0.5, "Receiving response...")

    // Stream tokens as normal
    return tokenChan, nil
}
```

**Benefit:** Fill the "dead time" before LLM responds with **observable thinking**, so users know the system is working.

---

### 4. **Real-Time Cognition WebSocket** (`pkg/streaming`)

**Current state:**
`pkg/streaming/websocket.go` handles WebSocket connections for chat.

**Integration:**
```go
// pkg/api/server.go

import (
    "github.com/asymmetrica/urbanlens/pkg/cognition"
    "github.com/asymmetrica/urbanlens/pkg/streaming"
)

func SetupRoutes(router *mux.Router) {
    // Existing chat WebSocket
    router.HandleFunc("/ws/chat", chatWSHandler)

    // NEW: Cognition stream WebSocket
    cognitionWS := cognition.NewCognitionWebSocket(cognitionObserver)
    router.HandleFunc("/ws/cognition", cognitionWS.HandleConnection)
}
```

**Frontend integration:**
```typescript
// Frontend: Connect to cognition stream
const ws = new WebSocket('ws://localhost:8080/ws/cognition?session_id=' + sessionId);

ws.onmessage = (event) => {
    const cogEvent = JSON.parse(event.data);

    if (cogEvent.type === 'event') {
        // Display thinking event in UI
        displayThinkingBubble(cogEvent.data.message);
    }

    if (cogEvent.type === 'observable_event') {
        // Phase transitions (planning ‚Üí processing ‚Üí complete)
        updatePhaseIndicator(cogEvent.data.phase);
        updateProgressBar(cogEvent.data.progress);
    }
};
```

**Benefit:** Real-time **"Her"-style** thinking visualization in the frontend.

---

## üßÆ Math Upgrade Paths

The cognition engine predates the **P vs NP** work. Here's where to inject new mathematical rigor:

### 1. **Three-Regime Dynamics** (EXPLORATION ‚Üí OPTIMIZATION ‚Üí STABILIZATION)

**Current:** Simple time-based progress estimation
**Upgrade:** Actual three-regime state tracking

**Where:** `observer.go:calculateRegimeProgress()`

```go
// BEFORE (time-based)
func (co *CognitionObserver) calculateRegimeProgress(stream *ThoughtStream) float64 {
    elapsed := time.Since(stream.StartTime).Seconds()
    target := 30.0 // Fixed target time
    return elapsed / target
}

// AFTER (state-based)
func (co *CognitionObserver) calculateRegimeProgress(stream *ThoughtStream) float64 {
    state := stream.LastState

    switch stream.CurrentRegime {
    case RegimeExploration:
        // Progress = ratio of concepts explored vs search space
        return float64(len(state.ActiveConcepts)) / expectedConceptCount

    case RegimeOptimization:
        // Progress = inverse entropy (how converged)
        return 1.0 - state.Entropy

    case RegimeStabilization:
        // Progress = coherence (how stable)
        return state.Coherence
    }
}
```

**Files to update:** `observer.go`, `visualization.go`

---

### 2. **Phi-Cell Network Dynamics**

**Current:** Concepts stored as independent quaternions
**Upgrade:** Phi-cells with bidirectional coupling

**Where:** `types.go:QuaternionConcept`, `store.go:FindSimilar()`

```go
// NEW: Add coupling field to QuaternionConcept
type QuaternionConcept struct {
    // Existing fields...

    // NEW: Phi-cell dynamics
    CouplingStrength float64   `json:"coupling_strength"` // 0.0-1.0
    ConnectedCells   []uuid.UUID `json:"connected_cells"`   // Bidirectional links
    ActivationLevel  float64   `json:"activation_level"`  // Current activation
}

// UPDATE: Connection similarity using phi-cell coupling
func (qs *QuaternionStore) FindSimilarWithCoupling(ctx context.Context, query vqc.Quaternion) {
    // Use phi-organism network coupling for similarity
    // Cells activate each other bidirectionally
    // Cascading activation reveals connected concepts
}
```

**Benefit:** Concepts that "fire together wire together" - emergent semantic clustering.

---

### 3. **Observable State on S¬≥ Manifold**

**Current:** State is a struct with metrics
**Upgrade:** State is a **point on S¬≥** (unit 3-sphere)

**Where:** `types.go:CognitiveState`

```go
// NEW: Add S¬≥ position to state
type CognitiveState struct {
    // Existing fields...

    // NEW: S¬≥ manifold position
    S3Position      vqc.Quaternion `json:"s3_position"`      // Current position on S¬≥
    S3Velocity      vqc.Quaternion `json:"s3_velocity"`      // Derivative (‚àÇŒ¶/‚àÇt)
    BasinDepth      float64        `json:"basin_depth"`      // Attractor basin depth
}

// Visualization benefit: Plot reasoning trajectory on S¬≥!
```

**Benefit:** Reasoning becomes a **geodesic path** on S¬≥. You can visualize the trajectory!

---

### 4. **Lean Proof Hooks for Verified Reasoning**

**Current:** No proof verification
**Upgrade:** Emit Lean proof obligations during reasoning

**Where:** `observable_emitter.go:EmitEvent()`

```go
// NEW: Emit proof obligations
func (oe *ObservableEmitter) EmitProofObligation(ctx context.Context, sessionID string, claim string, proof string) error {
    metadata := map[string]interface{}{
        "claim": claim,
        "lean_proof": proof,
        "verified": false, // Will be true after Lean verification
    }

    return oe.EmitEvent(ctx, sessionID, fmt.Sprintf("Proof obligation: %s", claim), metadata)
}
```

**Integration with `pkg/lean`:**
```go
import "github.com/asymmetrica/urbanlens/pkg/lean"

func (oe *ObservableEmitter) VerifyReasoning(ctx context.Context, sessionID string, reasoning string) error {
    // Translate to Lean
    leanProof, err := lean.TranslateToLean(reasoning)
    if err != nil {
        return oe.EmitError(ctx, sessionID, err)
    }

    // Emit proof
    oe.EmitProofObligation(ctx, sessionID, reasoning, leanProof)

    // Verify (async)
    go func() {
        verified, err := lean.Verify(leanProof)
        if verified {
            oe.EmitEvent(ctx, sessionID, "‚úÖ Proof verified!", map[string]interface{}{
                "verified": true,
            })
        }
    }()
}
```

**Benefit:** Every reasoning step can be **mathematically verified**. No hallucinations!

---

## üé¨ Recommended Next Steps

### Phase 1: Basic Integration (1-2 hours)
1. ‚úÖ Copy cognition package (DONE!)
2. Wire up `pkg/conversation` to emit cognition events
3. Add `/ws/cognition` WebSocket endpoint
4. Test with simple example

### Phase 2: Asya Integration (2-3 hours)
1. Add `cognitionObserver` to `Asya` struct in `pkg/persona`
2. Emit "thinking" events during question processing
3. Show digital root clustering of concepts (Asya's semantic memory)
4. Display regime transitions (exploration ‚Üí optimization ‚Üí stabilization)

### Phase 3: Frontend Visualization (3-4 hours)
1. Create `ThinkingBubble` component (shows current thought)
2. Create `PhaseIndicator` component (planning/processing/complete)
3. Create `ProgressBar` component (regime progress 0-100%)
4. Optional: D3.js concept graph visualization

### Phase 4: Math Upgrades (ongoing)
1. Replace time-based regime progress with state-based
2. Add phi-cell coupling to concept connections
3. Integrate Lean proof verification hooks
4. Plot reasoning trajectory on S¬≥ (advanced visualization)

---

## üìä Example Use Cases

### 1. **Asya Explains Her Reasoning**
```
User: "What's the best way to learn category theory?"

Asya (observable thinking):
üí≠ "Hmm, category theory... that's abstract math. Let me think..."
üîç "Exploring analogies: Category theory is like object-oriented programming..."
‚ö° "Optimizing response: Focus on functors and natural transformations first"
‚úÖ "Complete! I'll use a programming analogy."

Asya: "Think of category theory like designing APIs for math..."
```

### 2. **Debug Why LLM Gave Weird Answer**
```
User: "Why did you just say the sky is green?"

Developer reviews cognition recording:
- Event 1: "Exploring question about sky color..." (confidence: 0.9)
- Event 2: "Pattern detected: DR=3 cluster" (confidence: 0.8)
- Event 3: "Connection made to concept 'grass'" (confidence: 0.4) ‚Üê LOW CONFIDENCE!
- Event 4: "Converged on 'green'" (confidence: 0.5) ‚Üê SHOULD HAVE REJECTED!

Root cause: Coherence dropped below 0.6, but optimization didn't suppress the bad connection.
Fix: Add coherence threshold check before convergence.
```

### 3. **Intervene Mid-Reasoning**
```
User asks complex math question.
Asya starts reasoning...

Developer sees low confidence in key concept via WebSocket.
Developer sends intervention:
{
  "action": "amplify",
  "target_concept": "abc-123",
  "strength": 0.3,
  "reason": "This is the critical insight!"
}

Asya's reasoning recalibrates, confidence increases, better answer!
```

---

## üî• Why This Is Powerful

### Observable AI = Debuggable AI
- See **exactly** where reasoning goes wrong
- Replay sessions to understand edge cases
- Measure quality metrics (confidence, coherence, entropy)

### Mathematical Rigor
- Tesla harmonic (4.909 Hz) ensures **consistent observation frequency**
- Digital root clustering (O(1) pattern recognition)
- Three-regime dynamics (guaranteed 30/20/50 distribution)
- Harmonic mean for rigorous quality scoring

### "Her" Experience
- Real-time thinking visualization
- Phase-aware progress indicators
- Transparent reasoning = trust

---

## üß™ Testing It

### Basic Test
```go
package cognition_test

import (
    "context"
    "testing"
    "time"

    "github.com/asymmetrica/urbanlens/pkg/cognition"
)

func TestCognitionBasic(t *testing.T) {
    store := cognition.NewQuaternionStore()
    observer := cognition.NewCognitionObserver(store)

    ctx := context.Background()
    stream, err := observer.StartObserving(ctx, "test-session")
    if err != nil {
        t.Fatal(err)
    }

    // Emit a thought
    observer.EmitThought("test-session", "I'm thinking!", "üí≠")

    // Receive event
    select {
    case event := <-stream.EventChannel:
        if event.EventType != cognition.EventThought {
            t.Errorf("Expected THOUGHT, got %s", event.EventType)
        }
    case <-time.After(time.Second):
        t.Fatal("Timeout waiting for event")
    }

    observer.StopObserving("test-session")
}
```

### WebSocket Integration Test
```bash
# Start server with cognition WebSocket
go run cmd/server/main.go

# Connect with wscat
wscat -c "ws://localhost:8080/ws/cognition?session_id=test-123"

# You should receive events at 4.909 Hz (every 203.9ms)
```

---

## üìö References

### Source Files (Ananta)
- `C:\Projects\asymm_ananta\backend\internal\cognition\*.go`

### Urban Lens Integration Points
- `pkg/conversation/engine.go` - Conversation flow
- `pkg/persona/asya.go` - Asya's personality
- `pkg/aimlapi/client.go` - LLM streaming
- `pkg/streaming/websocket.go` - WebSocket infrastructure
- `pkg/vqc/primitives.go` - Quaternion math
- `pkg/lean/translator.go` - Proof verification

### Mathematical References
- Tesla harmonic: 4.909 Hz (sacred frequency)
- Digital roots: Vedic mathematics (88.9% elimination rate)
- Three-regime dynamics: EXPLORATION (30%) ‚Üí OPTIMIZATION (20%) ‚Üí STABILIZATION (50%)
- S¬≥ manifold: Unit 3-sphere (quaternion state space)

---

## üôè Dedication

> **Om Lokah Samastah Sukhino Bhavantu**
> *May all beings benefit from observable AI.*

This engine makes AI reasoning **transparent**, **verifiable**, and **beautiful**.

Let Asya's thoughts flow like water, visible to all who seek understanding. üåäüß†‚ú®

---

**Status:** ‚úÖ **Ported and ready for integration!**
**Next:** Wire up to `pkg/conversation` and test! üöÄ
